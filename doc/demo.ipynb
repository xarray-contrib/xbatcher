{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sticky-exhibit",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "Author: Cindy Chiao\n",
    "\n",
    "## What is xbatcher? \n",
    "Xbatcher is a small library for iterating through Xarray objects (DataArrays and Datasets) in batches. The goal is to make it easy to feed Xarray objects to machine learning libraries such as Keras and PyTorch. \n",
    "\n",
    "## What is included in this notebook?\n",
    "* showcase current abilities with example data \n",
    "* brief discussion of current development track and ideas for future work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xbatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-sense",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "Here we will load an example dataset from a global climate model. The data is from the _historical_ experiment from CMIP6 and represents 60 days of daily max air temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = \"az://carbonplan-share/example_cmip6_data.zarr\"\n",
    "ds = xr.open_dataset(\n",
    "    store,\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    backend_kwargs={\"storage_options\": {\"account_name\": \"carbonplan\"}},\n",
    ")\n",
    "\n",
    "# the attributes contain a lot of useful information, but clutter the print out when we inspect the outputs\n",
    "# throughout this demo, clearing it to avoid confusion\n",
    "ds.attrs = {}\n",
    "\n",
    "# inspect the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first time dimension\n",
    "ds.isel(time=0).tasmax.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-marsh",
   "metadata": {},
   "source": [
    "## Batch generation\n",
    "\n",
    "Xbatcher's `BatchGenerator` can be used to generate batches with several arguments controlling the exact behavior.\n",
    "\n",
    "The `input_dims` argument takes a dictionary specifying the size of the inputs in each dimension. For example, `{'time': 10}` means that each of the input sample will have 10 time points, while all other dimensions are flattened to a \"sample\" dimension\n",
    "\n",
    "Note that even though `ds` in this case only has one variable, the function can operate on multiple variables at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoint_in_each_sample = 10\n",
    "\n",
    "bgen = xbatcher.BatchGenerator(\n",
    "    ds=ds,\n",
    "    input_dims={\"time\": n_timepoint_in_each_sample},\n",
    ")\n",
    "\n",
    "print(f\"{len(bgen)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546aed21-3931-46b5-910e-c43498b51e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = bgen[0]\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-night",
   "metadata": {},
   "source": [
    "We can verify that the outputs have the expected shapes. \n",
    "\n",
    "For example, there are 60 time points in our input dataset, we're asking 10 timepoints in each batch, thus expecting 6 batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_n_batch = len(ds.time) / n_timepoint_in_each_sample\n",
    "print(f\"Expecting {expected_n_batch} batches, getting {len(bgen)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-kennedy",
   "metadata": {},
   "source": [
    "There are 145 lat points and 192 lon points, thus we're expecting 145 * 192 = 27840 samples in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_batch_size = len(ds.lat) * len(ds.lon)\n",
    "print(\n",
    "    f\"Expecting {expected_batch_size} samples per batch, getting {len(batch.sample)} samples per batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-gazette",
   "metadata": {},
   "source": [
    "## Controlling the size/shape of batches\n",
    "\n",
    "We can use `batch_dims` and `concat_input_dims` options to control how many sample ends up in each batch. For example, we can specify 10 time points for each sample, but 20 time points in each batch this should yield half as many batches and twice as many samples in a batch as the example above note the difference in dimension name in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoint_in_each_sample = 10\n",
    "n_timepoint_in_each_batch = 20\n",
    "\n",
    "bgen = xbatcher.BatchGenerator(\n",
    "    ds=ds,\n",
    "    input_dims={\"time\": n_timepoint_in_each_sample},\n",
    "    batch_dims={\"time\": n_timepoint_in_each_batch},\n",
    "    concat_input_dims=True,\n",
    ")\n",
    "\n",
    "print(f\"{len(bgen)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d962e-2b9e-4e25-95e3-a922bfac3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgen[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "spectacular-reading",
   "metadata": {},
   "source": [
    "## Last batch behavior\n",
    "\n",
    "If the input ds is not divisible by the specified `input_dims`, the remainder will be discarded instead of having a fractional batch. See https://github.com/xarray-contrib/xbatcher/discussions/82 for more on this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoint_in_batch = 31\n",
    "\n",
    "bgen = xbatcher.BatchGenerator(ds=ds, input_dims={\"time\": n_timepoint_in_batch})\n",
    "\n",
    "for batch in bgen:\n",
    "    print(f\"last time point in ds    is {ds.time[-1].values}\")\n",
    "    print(f\"last time point in batch is {batch.time[-1].values}\")\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-islam",
   "metadata": {},
   "source": [
    "## Overlapping inputs\n",
    "\n",
    "In the example above, all samples have distinct time points. That is, for any lat/lon pixel, sample 1 has time points 1-10, sample 2 has time point 11-20, and they do not overlap \n",
    "however, in many machine learning applications, we will want overlapping samples (e.g. sample 1 has time points 1-10, sample 2 has time points 2-11, and so on). We can use the `input_overlap` argument to get this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoint_in_each_sample = 10\n",
    "n_timepoint_in_each_batch = 20\n",
    "input_overlap = 9\n",
    "\n",
    "bgen = xbatcher.BatchGenerator(\n",
    "    ds=ds,\n",
    "    input_dims={\"time\": n_timepoint_in_each_sample},\n",
    "    batch_dims={\"time\": n_timepoint_in_each_batch},\n",
    "    concat_input_dims=True,\n",
    "    input_overlap={\"time\": input_overlap},\n",
    ")\n",
    "\n",
    "batch = bgen[0]\n",
    "\n",
    "print(f\"{len(bgen)} batches\")\n",
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "harmful-benefit",
   "metadata": {},
   "source": [
    "We can inspect the samples in a batch for a lat/lon pixel, noting that the overlap applies across batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = -90\n",
    "lon = 0\n",
    "pixel = batch.sel(lat=lat, lon=lon)\n",
    "display(pixel)\n",
    "\n",
    "print(\n",
    "    f\"sample 1 goes from {pixel.isel(input_batch=0).time[0].values} to {pixel.isel(input_batch=0).time[-1].values}\"\n",
    ")\n",
    "print(\n",
    "    f\"sample 2 goes from {pixel.isel(input_batch=1).time[0].values} to {pixel.isel(input_batch=1).time[-1].values}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-telephone",
   "metadata": {},
   "source": [
    "## Example applications\n",
    "\n",
    "These batches can then be used to train a downstream machine learning model while preserving the indices of these sample. \n",
    "\n",
    "As an example, let's say we want to train a simple CNN model to predict the max air temprature for each day at each lat/lon pixel. To predict the temperature at lat/lon/time of (i, j, t), we'll use features including the temperature of a 9 x 9 grid centered at (i, j), from times t-10 to t-1 (shape of input should be (n_samples_in_each_batch, 9, 9, 9)). Note that in this example, we subset the dataset to a smaller domain for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgen = xbatcher.BatchGenerator(\n",
    "    ds=ds[[\"tasmax\"]].isel(lat=slice(0, 18), lon=slice(0, 18), time=slice(0, 30)),\n",
    "    input_dims={\"lat\": 9, \"lon\": 9, \"time\": 10},\n",
    "    batch_dims={\"lat\": 18, \"lon\": 18, \"time\": 15},\n",
    "    concat_input_dims=True,\n",
    "    input_overlap={\"lat\": 8, \"lon\": 8, \"time\": 9},\n",
    ")\n",
    "\n",
    "for i, batch in enumerate(bgen):\n",
    "    print(f\"batch {i}\")\n",
    "    # make sure the ordering of dimension is consistent\n",
    "    batch = batch.transpose(\"input_batch\", \"lat_input\", \"lon_input\", \"time_input\")\n",
    "\n",
    "    # only use the first 9 time points as features, since the last time point is the label to be predicted\n",
    "    features = batch.tasmax.isel(time_input=slice(0, 9))\n",
    "    # select the center pixel at the last time point to be the label to be predicted\n",
    "    # the actual lat/lon/time for each of the sample can be accessed in labels.coords\n",
    "    labels = batch.tasmax.isel(lat_input=5, lon_input=5, time_input=9)\n",
    "\n",
    "    print(\"feature shape\", features.shape)\n",
    "    print(\"label shape\", labels.shape)\n",
    "    print(\"shape of lat of each sample\", labels.coords[\"lat\"].shape)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-closer",
   "metadata": {},
   "source": [
    "We can also use the Xarray's \"stack\" method to transform these into 2D inputs (n_samples, n_features) suitable for other machine learning algorithms implemented in libraries such as [sklearn](https://scikit-learn.org/stable/) and [xgboost](https://xgboost.readthedocs.io/en/stable/). In this case, we are expecting 9 x 9 x 9 = 729 features total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(bgen):\n",
    "    print(f\"batch {i}\")\n",
    "    # make sure the ordering of dimension is consistent\n",
    "    batch = batch.transpose(\"input_batch\", \"lat_input\", \"lon_input\", \"time_input\")\n",
    "\n",
    "    # only use the first 9 time points as features, since the last time point is the label to be predicted\n",
    "    features = batch.tasmax.isel(time_input=slice(0, 9))\n",
    "    features = features.stack(features=[\"lat_input\", \"lon_input\", \"time_input\"])\n",
    "\n",
    "    # select the center pixel at the last time point to be the label to be predicted\n",
    "    # the actual lat/lon/time for each of the sample can be accessed in labels.coords\n",
    "    labels = batch.tasmax.isel(lat_input=5, lon_input=5, time_input=9)\n",
    "\n",
    "    print(\"feature shape\", features.shape)\n",
    "    print(\"label shape\", labels.shape)\n",
    "    print(\"shape of lat of each sample\", labels.coords[\"lat\"].shape, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "persistent-culture",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "There are many additional useful features that were yet to be implemented in the context of batch generation for downstream machine learning model training purposes. One of the current efforts is to improve the set of data loaders. \n",
    "\n",
    "Additional features of interest can include: \n",
    "\n",
    "1. Shuffling/randomization of samples across batches. It is often desirable for each batch to be grouped randomly instead of along a specific dimension. \n",
    "\n",
    "2. Be efficient in terms of memory usage. In the case where overlap is enabled, each sample would comprised of mostly repetitive values compared to adjacent samples. It would be beneficial if each batch/sample is generated lazily to avoid storing these extra duplicative values. \n",
    "\n",
    "3. Handling preprocessing steps. For example, data augmentation, scaling/normalization, outlier detection, etc. \n",
    "\n",
    "\n",
    "More thoughts on 1. can be found in [this discussion](https://github.com/xarray-contrib/xbatcher/discussions/78). Interested users are welcomed to comment or submit other issues in GitHub. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('xbatcher-tests')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) \n[Clang 12.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "64c578a0a9f6dde4e1dfaddaa39417770d5e50fec039804eaf1eb97ef756c00c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
